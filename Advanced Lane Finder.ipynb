{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <h1 style=\"font-family: sans-serif; padding: 20px 0; text-align: center\">Project video</h1>\n",
       "    <div style=\"width: 100%\">\n",
       "        <video style=\"width: inherit\" controls autoplay loop src=\"test_videos/project_video.mp4\"/>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "    <h1 style=\"font-family: sans-serif; padding: 20px 0; text-align: center\">Project video</h1>\n",
    "    <div style=\"width: 100%\">\n",
    "        <video style=\"width: inherit\" controls autoplay loop src=\"test_videos/project_video.mp4\"/>\n",
    "    </div>\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lane Finder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Camera import LaneCamera\n",
    "from LaneIsolator import LaneIsolator\n",
    "from SlidingWindowDetector import SlidingWindowDetector\n",
    "from skimage.draw import polygon\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class LaneFinder(object):\n",
    "    def __init__(self, camera_input, camera_calibration_file=None):\n",
    "        self.camera = LaneCamera(camera_input)\n",
    "        self.video_shape = self.camera.get_frame().shape\n",
    "        self.isolator = LaneIsolator()\n",
    "        self.detector = SlidingWindowDetector()\n",
    "        if camera_calibration_file:\n",
    "            self.camera.load_camera_calibration(camera_calibration_file)\n",
    "        \n",
    "    def request_video_frame(self):\n",
    "        frame = self.camera.get_frame()\n",
    "        view = self.camera.birds_eye_view(frame)\n",
    "        lanes_bitmap = self.isolator.isolate_lines(view)\n",
    "        lane_poly = self.detector.get_lane_poly(lanes_bitmap)\n",
    "        return (lane_poly, frame)\n",
    "    \n",
    "    def get_lane_overlay(self, frame, poly, color=(0, 255, 0)):\n",
    "        # Turn our poynomials into functions\n",
    "        p_left = np.poly1d(poly[0])\n",
    "        p_right = np.poly1d(poly[1])\n",
    "        \n",
    "        # Generate y points\n",
    "        y = np.linspace(0, self.video_shape[0]-1)\n",
    "        \n",
    "        # Get x values for each generated y points\n",
    "        left_x = [p_left(y) for y in y]\n",
    "        right_x = [p_right(y) for y in y]\n",
    "        \n",
    "        # Create an empty image\n",
    "        img = np.zeros(self.video_shape, dtype=np.uint8)\n",
    "        \n",
    "        # Turn our data into usable vertices\n",
    "        left = np.array(list(zip(y, left_x)))\n",
    "        right = np.flipud(np.array(list(zip(y, right_x))))\n",
    "        \n",
    "        # Concatenate all our vertices into one array\n",
    "        vertices = np.concatenate((left, right))\n",
    "        \n",
    "        # Define a polygon from our vertices\n",
    "        rr, cc = polygon(vertices[:, 0].clip(0, self.video_shape[0]-2), vertices[:, 1])\n",
    "        \n",
    "        # Fill our polygon\n",
    "        img[rr, cc] = color\n",
    "        \n",
    "        # Inverse perspective transform and return\n",
    "        return self.camera.inverse_birds_eye_view(img)\n",
    "    \n",
    "    def get_lane_curvature(self, poly):\n",
    "        p_left = poly[0]\n",
    "        p_right = poly[1]\n",
    "        p_left_m = poly[2]\n",
    "        p_right_m = poly[3]\n",
    "        y_val = self.video_shape[1]\n",
    "        curve_left = self._curvature(y_val, p_left_m[0], p_left_m[1])\n",
    "        curve_right = self._curvature(y_val, p_right_m[0], p_right_m[1])\n",
    "        return (curve_left, curve_right)\n",
    "    \n",
    "    def _curvature(self, y, A, B):\n",
    "        R = (1 + (2*A*y + B)**2)**(3/2)\n",
    "        R = R/np.absolute(2 * A)\n",
    "        return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video output2.mp4\n",
      "[MoviePy] Writing video output2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/51 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/51 [00:00<00:34,  1.43it/s]\u001b[A\n",
      "  4%|▍         | 2/51 [00:01<00:34,  1.43it/s]\u001b[A\n",
      "  6%|▌         | 3/51 [00:02<00:33,  1.43it/s]\u001b[A\n",
      "  8%|▊         | 4/51 [00:02<00:32,  1.44it/s]\u001b[A\n",
      " 10%|▉         | 5/51 [00:03<00:31,  1.44it/s]\u001b[A\n",
      " 12%|█▏        | 6/51 [00:04<00:30,  1.45it/s]\u001b[A\n",
      " 14%|█▎        | 7/51 [00:04<00:30,  1.46it/s]\u001b[A\n",
      " 16%|█▌        | 8/51 [00:05<00:29,  1.47it/s]\u001b[A\n",
      " 18%|█▊        | 9/51 [00:06<00:28,  1.48it/s]\u001b[A\n",
      " 20%|█▉        | 10/51 [00:06<00:27,  1.47it/s]\u001b[A\n",
      " 22%|██▏       | 11/51 [00:07<00:27,  1.47it/s]\u001b[A\n",
      " 24%|██▎       | 12/51 [00:08<00:26,  1.46it/s]\u001b[A\n",
      " 25%|██▌       | 13/51 [00:08<00:25,  1.47it/s]\u001b[A\n",
      " 27%|██▋       | 14/51 [00:09<00:24,  1.48it/s]\u001b[A\n",
      " 29%|██▉       | 15/51 [00:10<00:24,  1.49it/s]\u001b[A\n",
      " 31%|███▏      | 16/51 [00:10<00:23,  1.48it/s]\u001b[A\n",
      " 33%|███▎      | 17/51 [00:11<00:22,  1.48it/s]\u001b[A\n",
      " 35%|███▌      | 18/51 [00:12<00:22,  1.47it/s]\u001b[A\n",
      " 37%|███▋      | 19/51 [00:12<00:21,  1.48it/s]\u001b[A\n",
      " 39%|███▉      | 20/51 [00:13<00:21,  1.42it/s]\u001b[A\n",
      " 41%|████      | 21/51 [00:14<00:21,  1.42it/s]\u001b[A\n",
      " 43%|████▎     | 22/51 [00:15<00:20,  1.44it/s]\u001b[A\n",
      " 45%|████▌     | 23/51 [00:15<00:19,  1.44it/s]\u001b[A\n",
      " 47%|████▋     | 24/51 [00:16<00:18,  1.45it/s]\u001b[A\n",
      " 49%|████▉     | 25/51 [00:17<00:17,  1.46it/s]\u001b[A\n",
      " 51%|█████     | 26/51 [00:17<00:17,  1.46it/s]\u001b[A\n",
      " 53%|█████▎    | 27/51 [00:18<00:16,  1.47it/s]\u001b[A\n",
      " 55%|█████▍    | 28/51 [00:19<00:15,  1.47it/s]\u001b[A\n",
      " 57%|█████▋    | 29/51 [00:19<00:14,  1.48it/s]\u001b[A\n",
      " 59%|█████▉    | 30/51 [00:20<00:14,  1.48it/s]\u001b[A\n",
      " 61%|██████    | 31/51 [00:21<00:13,  1.47it/s]\u001b[A\n",
      " 63%|██████▎   | 32/51 [00:21<00:13,  1.41it/s]\u001b[A\n",
      " 65%|██████▍   | 33/51 [00:22<00:12,  1.43it/s]\u001b[A\n",
      " 67%|██████▋   | 34/51 [00:23<00:11,  1.45it/s]\u001b[A\n",
      " 69%|██████▊   | 35/51 [00:23<00:10,  1.47it/s]\u001b[A\n",
      " 71%|███████   | 36/51 [00:24<00:10,  1.48it/s]\u001b[A\n",
      " 73%|███████▎  | 37/51 [00:25<00:09,  1.49it/s]\u001b[A\n",
      " 75%|███████▍  | 38/51 [00:25<00:08,  1.48it/s]\u001b[A\n",
      " 76%|███████▋  | 39/51 [00:26<00:08,  1.45it/s]\u001b[A\n",
      " 78%|███████▊  | 40/51 [00:27<00:08,  1.36it/s]\u001b[A\n",
      " 80%|████████  | 41/51 [00:28<00:07,  1.37it/s]\u001b[A\n",
      " 82%|████████▏ | 42/51 [00:28<00:06,  1.39it/s]\u001b[A\n",
      " 84%|████████▍ | 43/51 [00:29<00:05,  1.39it/s]\u001b[A\n",
      " 86%|████████▋ | 44/51 [00:30<00:05,  1.39it/s]\u001b[A\n",
      " 88%|████████▊ | 45/51 [00:31<00:04,  1.40it/s]\u001b[A\n",
      " 90%|█████████ | 46/51 [00:31<00:03,  1.41it/s]\u001b[A\n",
      " 92%|█████████▏| 47/51 [00:32<00:02,  1.41it/s]\u001b[A\n",
      " 94%|█████████▍| 48/51 [00:33<00:02,  1.43it/s]\u001b[A\n",
      " 96%|█████████▌| 49/51 [00:33<00:01,  1.43it/s]\u001b[A\n",
      " 98%|█████████▊| 50/51 [00:34<00:00,  1.43it/s]\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: output2.mp4 \n",
      "\n",
      "CPU times: user 43.2 s, sys: 3.61 s, total: 46.8 s\n",
      "Wall time: 36 s\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lane_finder = LaneFinder(\"test_videos/project_video.mp4\", \n",
    "                         \"camera_cal/calibration_data.npy\")\n",
    "\n",
    "def process_image(image):\n",
    "    poly, frame = lane_finder.request_video_frame()\n",
    "    overlay = lane_finder.get_lane_overlay(frame, poly)\n",
    "    img = cv2.addWeighted(frame, 1, overlay, 0.6, 0)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    lane_curvature = lane_finder.get_lane_curvature(poly)\n",
    "    curvature_str1 = \"left lane curvature: {:.0f} m\".format(lane_curvature[0])\n",
    "    curvature_str2 = \"right lane curvature: {:.0f} m\".format(lane_curvature[1])\n",
    "    cv2.putText(img, curvature_str1,(100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 2)\n",
    "    cv2.putText(img, curvature_str2,(100, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 2)\n",
    "    return img\n",
    "\n",
    "clip = VideoFileClip('test_videos/project_video.mp4').subclip(0, 2)\n",
    "a_clip = clip.fl_image(process_image)\n",
    "%time a_clip.write_videofile(\"output2.mp4\", audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <h1 style=\"font-family: sans-serif; padding: 20px 0; text-align: center\">Output video</h1>\n",
       "    <div style=\"width: 100%\">\n",
       "        <video style=\"width: inherit\" controls autoplay loop src=\"output2.mp4\"/>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "    <h1 style=\"font-family: sans-serif; padding: 20px 0; text-align: center\">Output video</h1>\n",
    "    <div style=\"width: 100%\">\n",
    "        <video style=\"width: inherit\" controls autoplay loop src=\"output2.mp4\"/>\n",
    "    </div>\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
